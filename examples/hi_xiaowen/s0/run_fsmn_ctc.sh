#!/bin/bash
# Copyright 2021  Binbin Zhang(binbzha@qq.com)
#           2023  Jing Du(thuduj12@163.com)
#
# ç”¨æ³•ç¤ºä¾‹ï¼ˆæ³¨æ„ï¼šé€‰é¡¹å‚æ•°å¿…é¡»æ”¾åœ¨ä½ç½®å‚æ•°ä¹‹å‰ï¼‰:
#   bash run_fsmn_ctc.sh 2 2                                        # ä½¿ç”¨é»˜è®¤å®éªŒç›®å½• exp/fsmn_ctc
#   bash run_fsmn_ctc.sh --target_exp_dir exp/my_exp 2 2          # æŒ‡å®šå®éªŒç›®å½•ï¼ˆæ­£ç¡®ï¼‰
#   bash run_fsmn_ctc.sh 2 2 --target_exp_dir exp/my_exp          # é”™è¯¯ï¼é€‰é¡¹ä¼šè¢«å¿½ç•¥
#
# æ—¥å¿—æ–‡ä»¶ä¼šè‡ªåŠ¨ä¿å­˜åˆ°: <target_exp_dir>/logs/run_stage_<stage>_<stop_stage>_<timestamp>.log
# æ—¥å¿—åŒæ—¶è¾“å‡ºåˆ°ç»ˆç«¯å’Œæ–‡ä»¶ï¼ˆä½¿ç”¨ tee å‘½ä»¤ï¼‰

. ./path.sh

# è¿‡æ»¤ torchaudio å¼ƒç”¨è­¦å‘Š
export PYTHONWARNINGS="ignore::UserWarning"

# ä¿å­˜åŸå§‹å‚æ•°ç”¨äºæ—¥å¿—
original_args="$@"

stage=-1
stop_stage=-1
num_keywords=2599

config=conf/fsmn_ctc.yaml
norm_mean=true
norm_var=true
gpus="0"

checkpoint=
target_exp_dir=exp/fsmn_ctc
average_model=true
num_average=30

# å°è¯•ä»é…ç½®æ–‡ä»¶è¯»å– download_dir
if [ -f wayne_scripts/config.yaml ]; then
    config_download_dir=$(python tools/read_config.py download_dir 2>/dev/null)
    if [ $? -eq 0 ] && [ -n "$config_download_dir" ]; then
        download_dir="$config_download_dir"
        echo "âœ… ä» config.yaml è¯»å– download_dir: $download_dir"
    else
        download_dir=/home/data/datasets/kws/opensourced/nihaowenwen
        echo "âš ï¸  é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ download_dir: $download_dir"
    fi
else
    # download_dir=/mnt/52_disk/back/DuJing/data/nihaowenwen # your data dir
    # download_dir=/Users/wayne/Documents/work/code/project/ffalcon/kws/wekws/examples/hi_xiaowen/s0/data
    download_dir=/home/data/datasets/kws/opensourced/nihaowenwen
fi

. tools/parse_options.sh || exit 1;

# parse_options.sh å¤„ç†å®Œé€‰é¡¹åï¼Œå‰©ä½™çš„æ˜¯ä½ç½®å‚æ•°
if [ $# -ge 1 ]; then
  stage=$1
fi
if [ $# -ge 2 ]; then
  stop_stage=$2
fi

window_shift=50

# è®¾ç½®å®éªŒç›®å½•
dir=$target_exp_dir
if $average_model ;then
  score_checkpoint=$dir/avg_${num_average}.pt
else
  score_checkpoint=$dir/final.pt
fi

# åˆ›å»ºæ—¥å¿—ç›®å½•å’Œæ—¥å¿—æ–‡ä»¶
log_dir=$dir/logs
mkdir -p $log_dir

# ç”Ÿæˆæ—¥å¿—æ–‡ä»¶åï¼ˆå¸¦æ—¶é—´æˆ³ï¼‰
timestamp=$(date +"%Y%m%d_%H%M%S")
log_file=$log_dir/run_stage_${stage}_${stop_stage}_${timestamp}.log

# å¦‚æœè¿˜æ²¡æœ‰é‡å®šå‘åˆ° teeï¼ˆé¿å…é€’å½’ï¼‰
if [ -z "$LOG_REDIRECT_DONE" ]; then
  echo "ğŸ“ å®éªŒç›®å½•: $dir"
  echo "ğŸ“ æ—¥å¿—æ–‡ä»¶: $log_file"
  echo "================================================"
  export LOG_REDIRECT_DONE=1
  # é‡æ–°æ‰§è¡Œè„šæœ¬ï¼Œè¾“å‡ºåŒæ—¶åˆ°ç»ˆç«¯å’Œæ—¥å¿—æ–‡ä»¶
  exec > >(tee -a "$log_file") 2>&1
  # è®°å½•è„šæœ¬å¼€å§‹æ—¶é—´å’Œå‚æ•°
  echo "================================================"
  echo "ğŸš€ å¼€å§‹è¿è¡Œ: $(date)"
  echo "   å‘½ä»¤: bash $0 $original_args"
  echo "   Stage: $stage -> $stop_stage"
  echo "   å®éªŒç›®å½•: $dir"
  echo "   æ—¥å¿—æ–‡ä»¶: $log_file"
  echo "================================================"
fi

# å°†æµ®ç‚¹æ•° stage è½¬æ¢ä¸ºæ•´æ•°è¿›è¡Œæ¯”è¾ƒï¼ˆå¦‚æœæ˜¯æ•´æ•°åˆ™ç›´æ¥ä½¿ç”¨ï¼‰
if [ "$stage" = "1.5" ] || [ "$stop_stage" = "1.5" ]; then
  # Stage 1.5 æ˜¯ç‰¹æ®Šçš„ä¸­é—´ stageï¼Œå•ç‹¬å¤„ç†
  stage_int=999
  stop_stage_int=999
else
  stage_int=$(echo "$stage" | awk '{print int($1)}')
  stop_stage_int=$(echo "$stop_stage" | awk '{print int($1)}')
fi

if [ ${stage_int} -le -2 ] && [ ${stop_stage_int} -ge -2 ]; then
  echo "Download and extracte all datasets"
  local/mobvoi_data_download.sh --dl_dir $download_dir
fi


if [ ${stage_int} -le -1 ] && [ ${stop_stage_int} -ge -1 ]; then
  echo "Preparing datasets..."
  mkdir -p dict
  echo "<FILLER> -1" > dict/dict.txt
  echo "<HI_XIAOWEN> 0" >> dict/dict.txt
  echo "<NIHAO_WENWEN> 1" >> dict/dict.txt
  awk '{print $1}' dict/dict.txt > dict/words.txt

  for folder in train dev test; do
    mkdir -p data/$folder
    for prefix in p n; do
      mkdir -p data/${prefix}_$folder
      json_path=$download_dir/mobvoi_hotword_dataset_resources/${prefix}_$folder.json
      local/prepare_data.py $download_dir/mobvoi_hotword_dataset $json_path \
        dict/dict.txt data/${prefix}_$folder
    done
    cat data/p_$folder/wav.scp data/n_$folder/wav.scp > data/$folder/wav.scp
    cat data/p_$folder/text data/n_$folder/text > data/$folder/text
    rm -rf data/p_$folder data/n_$folder
  done
fi

if [ ${stage_int} -le -0 ] && [ ${stop_stage_int} -ge -0 ]; then
# Here we Use Paraformer Large(https://www.modelscope.cn/models/damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/summary)
# to transcribe the negative wavs, and upload the transcription to modelscope.
  git clone https://www.modelscope.cn/datasets/thuduj12/mobvoi_kws_transcription.git
  for folder in train dev test; do
    if [ -f data/$folder/text ];then
      mv data/$folder/text data/$folder/text.label
    fi
    cp mobvoi_kws_transcription/$folder.text data/$folder/text
  done

  # and we also copy the tokens and lexicon that used in
  # https://modelscope.cn/models/damo/speech_charctc_kws_phone-xiaoyun/summary
  awk '{print $1, $2-1}' mobvoi_kws_transcription/tokens.txt > dict/dict.txt
  sed -i 's/& 1/<filler> 1/' dict/dict.txt
  echo '<SILENCE>' > dict/words.txt
  echo '<EPS>' >> dict/words.txt
  echo '<BLK>' >> dict/words.txt
fi

if [ ${stage_int} -le 1 ] && [ ${stop_stage_int} -ge 1 ]; then
  echo "Compute CMVN and Format datasets"
  tools/compute_cmvn_stats.py --num_workers 16 --train_config $config \
    --in_scp data/train/wav.scp \
    --out_cmvn data/train/global_cmvn

  for x in train dev test; do
    tools/wav_to_duration.sh --nj 8 data/$x/wav.scp data/$x/wav.dur

    # Here we use tokens.txt and lexicon.txt to convert txt into index
    tools/make_list.py data/$x/wav.scp data/$x/text \
      data/$x/wav.dur data/$x/data.list
  done
fi

# Stage 1.5 (Optional): Build metadata database for WebUI
# This stage creates a SQLite database for fast searching and filtering
# Run separately: bash run_fsmn_ctc.sh 1.5 1.5
if [ ${stage} == "1.5" ]; then
  echo "Building metadata database for WebUI..."
  python3 tools/generate_metadata_db.py --output-db data/metadata.db --force
  echo ""
  echo "To start the WebUI, run:"
  echo "  cd wayne_scripts && sh stage_1.5_webui.sh"
  echo ""
  exit 0
fi

if [ ${stage_int} -le 2 ] && [ ${stop_stage_int} -ge 2 ]; then

  echo "Use the base model from modelscope"
  if [ ! -d speech_charctc_kws_phone-xiaoyun ] ;then
      git lfs install
      git clone https://www.modelscope.cn/damo/speech_charctc_kws_phone-xiaoyun.git
  fi
  checkpoint=speech_charctc_kws_phone-xiaoyun/train/base.pt
  cp speech_charctc_kws_phone-xiaoyun/train/feature_transform.txt.80dim-l2r2 data/global_cmvn.kaldi

  echo "Start training ..."
  mkdir -p $dir
  cmvn_opts=
  $norm_mean && cmvn_opts="--cmvn_file data/global_cmvn.kaldi"
  $norm_var && cmvn_opts="$cmvn_opts --norm_var"
  num_gpus=$(echo $gpus | awk -F ',' '{print NF}')

  # ä½¿ç”¨å½“å‰ conda ç¯å¢ƒçš„ pythonï¼Œè€Œéç³»ç»Ÿ python
  python -m torch.distributed.run --standalone --nnodes=1 --nproc_per_node=$num_gpus \
    wekws/bin/train.py --gpus $gpus \
      --config $config \
      --train_data data/train/data.list \
      --cv_data data/dev/data.list \
      --model_dir $dir \
      --num_workers 8 \
      --num_keywords $num_keywords \
      --min_duration 50 \
      --seed 666 \
      $cmvn_opts \
      ${checkpoint:+--checkpoint $checkpoint}
fi

if [ ${stage_int} -le 3 ] && [ ${stop_stage_int} -ge 3 ]; then
  echo "Do model average, Compute FRR/FAR ..."
  if $average_model; then
    python wekws/bin/average_model.py \
      --dst_model $score_checkpoint \
      --src_path $dir  \
      --num ${num_average} \
      --val_best
  fi
  result_dir=$dir/test_$(basename $score_checkpoint)
  mkdir -p $result_dir
  stream=false  # we detect keyword online with ctc_prefix_beam_search
  score_prefix=""
  if $stream ; then
    score_prefix=stream_
  fi
  python wekws/bin/${score_prefix}score_ctc.py \
    --config $dir/config.yaml \
    --test_data data/test/data.list \
    --gpu 0  \
    --batch_size 256 \
    --checkpoint $score_checkpoint \
    --score_file $result_dir/score.txt  \
    --num_workers 8  \
    --keywords "\u55e8\u5c0f\u95ee,\u4f60\u597d\u95ee\u95ee" \
    --token_file data/tokens.txt \
    --lexicon_file data/lexicon.txt

  python wekws/bin/compute_det_ctc.py \
      --keywords "\u55e8\u5c0f\u95ee,\u4f60\u597d\u95ee\u95ee" \
      --test_data data/test/data.list \
      --window_shift $window_shift \
      --step 0.001  \
      --score_file $result_dir/score.txt \
      --token_file data/tokens.txt \
      --lexicon_file data/lexicon.txt
fi


if [ ${stage_int} -le 4 ] && [ ${stop_stage_int} -ge 4 ]; then
  jit_model=$(basename $score_checkpoint | sed -e 's:.pt$:.zip:g')
  onnx_model=$(basename $score_checkpoint | sed -e 's:.pt$:.onnx:g')
  # For now, FSMN can not export to JITScript
#  python wekws/bin/export_jit.py \
#    --config $dir/config.yaml \
#    --checkpoint $score_checkpoint \
#    --jit_model $dir/$jit_model
  python wekws/bin/export_onnx.py \
    --config $dir/config.yaml \
    --checkpoint $score_checkpoint \
    --onnx_model $dir/$onnx_model
fi

# è„šæœ¬ç»“æŸæ—¥å¿—
if [ -n "$LOG_REDIRECT_DONE" ]; then
  echo ""
  echo "================================================"
  echo "âœ… è¿è¡Œå®Œæˆ: $(date)"
  echo "   å®éªŒç›®å½•: $dir"
  echo "   æ—¥å¿—æ–‡ä»¶: $log_file"
  echo "================================================"
fi
