#!/bin/bash
# Copyright 2026 Wayne
#
# çŸ¥è¯†è’¸é¦è®­ç»ƒè„šæœ¬ï¼šç”¨æ•™å¸ˆæ¨¡å‹ï¼ˆFSMN top20ï¼‰è’¸é¦è®­ç»ƒå­¦ç”Ÿæ¨¡å‹ï¼ˆFSMN-miniï¼‰
#
# ç”¨æ³•ç¤ºä¾‹ï¼ˆé€‰é¡¹å‚æ•°å¿…é¡»æ”¾åœ¨ä½ç½®å‚æ•°ä¹‹å‰ï¼‰:
#   bash run_distill.sh 2 2                                             # Stage 2: è’¸é¦è®­ç»ƒ
#   bash run_distill.sh 3 3                                             # Stage 3: æ¨¡å‹å¹³å‡ + è¯„æµ‹
#   bash run_distill.sh 2 3                                             # Stage 2+3: è’¸é¦è®­ç»ƒ + è¯„æµ‹
#   bash run_distill.sh --gpus "0,1" --kd_temperature 4.0 2 3         # è‡ªå®šä¹‰å‚æ•°
#   bash run_distill.sh --teacher_checkpoint exp/xxx/79.pt 2 3        # æŒ‡å®šæ•™å¸ˆæ¨¡å‹
#
# æ—¥å¿—æ–‡ä»¶ä¼šè‡ªåŠ¨ä¿å­˜åˆ°: <target_exp_dir>/logs/run_distill_stage_<stage>_<stop_stage>_<timestamp>.log

. ./path.sh

# è¿‡æ»¤ torchaudio å¼ƒç”¨è­¦å‘Š
export PYTHONWARNINGS="ignore::UserWarning"

# ä¿å­˜åŸå§‹å‚æ•°ç”¨äºæ—¥å¿—
original_args="$@"

stage=2
stop_stage=3

# ---- æ•™å¸ˆæ¨¡å‹ ----
teacher_checkpoint=exp/fsmn_ctc_top20_weight_surgery/79.pt
teacher_config=  # ä¸ºç©ºåˆ™ä» teacher_checkpoint ç›®å½•è‡ªåŠ¨æ¨å¯¼

# ---- å­¦ç”Ÿæ¨¡å‹ ----
student_config=conf/fsmn_ctc_student_mini.yaml
num_keywords=20
dict_dir="dict_top20"

# ---- å®éªŒç›®å½• ----
target_exp_dir=exp/fsmn_ctc_distill_mini

# ---- è®­ç»ƒå‚æ•° ----
gpus="0,1,2,3"
norm_mean=true
norm_var=true
seed=666

# ---- è’¸é¦å‚æ•° ----
kd_temperature=2.0
kd_lambda_init=0.7
kd_lambda_final=0.5
kd_lambda_switch_epoch=20
finetune_epochs=10
init_from_teacher=false

# ---- è¯„æµ‹å‚æ•° ----
average_model=true
num_average=30
window_shift=50
token_file="mobvoi_kws_transcription/tokens.txt"
lexicon_file="mobvoi_kws_transcription/lexicon.txt"

. tools/parse_options.sh || exit 1;

# parse_options.sh å¤„ç†å®Œé€‰é¡¹åï¼Œå‰©ä½™çš„æ˜¯ä½ç½®å‚æ•°
if [ $# -ge 1 ]; then
  stage=$1
fi
if [ $# -ge 2 ]; then
  stop_stage=$2
fi

dir=$target_exp_dir
if $average_model; then
  score_checkpoint=$dir/avg_${num_average}.pt
else
  score_checkpoint=$dir/final.pt
fi

# åˆ›å»ºæ—¥å¿—ç›®å½•å’Œæ—¥å¿—æ–‡ä»¶
log_dir=$dir/logs
mkdir -p $log_dir

timestamp=$(date +"%Y%m%d_%H%M%S")
log_file=$log_dir/run_distill_stage_${stage}_${stop_stage}_${timestamp}.log

# å¦‚æœè¿˜æ²¡æœ‰é‡å®šå‘åˆ° teeï¼ˆé¿å…é€’å½’ï¼‰
if [ -z "$LOG_REDIRECT_DONE" ]; then
  echo "ğŸ“ å®éªŒç›®å½•: $dir"
  echo "ğŸ“ æ—¥å¿—æ–‡ä»¶: $log_file"
  echo "================================================"
  export LOG_REDIRECT_DONE=1
  exec > >(tee -a "$log_file") 2>&1
  echo "================================================"
  echo "ğŸš€ å¼€å§‹è¿è¡Œ: $(date)"
  echo "   å‘½ä»¤: bash $0 $original_args"
  echo "   Stage: $stage -> $stop_stage"
  echo "   å®éªŒç›®å½•: $dir"
  echo "   æ—¥å¿—æ–‡ä»¶: $log_file"
  echo "================================================"
fi

stage_int=$(echo "$stage" | awk '{print int($1)}')
stop_stage_int=$(echo "$stop_stage" | awk '{print int($1)}')

# ================================================================
# Stage 2: è’¸é¦è®­ç»ƒ
# ================================================================
if [ ${stage_int} -le 2 ] && [ ${stop_stage_int} -ge 2 ]; then
  echo ""
  echo "================================================"
  echo "ğŸ“ Stage 2: çŸ¥è¯†è’¸é¦è®­ç»ƒ"
  echo "================================================"
  echo "æ•™å¸ˆæ¨¡å‹:       $teacher_checkpoint"
  echo "æ•™å¸ˆé…ç½®:       ${teacher_config:-auto}"
  echo "å­¦ç”Ÿé…ç½®:       $student_config"
  echo "è¯è¡¨ç›®å½•:       $dict_dir"
  echo "è¾“å‡ºå…³é”®è¯æ•°:   $num_keywords"
  echo "è’¸é¦æ¸©åº¦ T:     $kd_temperature"
  echo "Lambda åˆå§‹:    $kd_lambda_init"
  echo "Lambda åæœŸ:    $kd_lambda_final"
  echo "Lambda åˆ‡æ¢:    epoch $kd_lambda_switch_epoch"
  echo "çº¯CTCæ”¶å°¾:     æœ€å $finetune_epochs epoch"
  echo "æ•™å¸ˆæƒé‡åˆå§‹åŒ–: $init_from_teacher"
  echo "GPU:            $gpus"
  echo "================================================"
  echo ""

  # æ£€æŸ¥æ•™å¸ˆæ¨¡å‹æ–‡ä»¶
  if [ ! -f "$teacher_checkpoint" ]; then
    echo "âŒ é”™è¯¯: æ•™å¸ˆæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: $teacher_checkpoint"
    exit 1
  fi

  # æ£€æŸ¥å­¦ç”Ÿé…ç½®
  if [ ! -f "$student_config" ]; then
    echo "âŒ é”™è¯¯: å­¦ç”Ÿé…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $student_config"
    exit 1
  fi

  # æ£€æŸ¥ CMVN æ–‡ä»¶
  if [ ! -f data/global_cmvn.kaldi ]; then
    echo "âš ï¸  CMVN æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä»é¢„è®­ç»ƒæ¨¡å‹å¤åˆ¶..."
    if [ -f speech_charctc_kws_phone-xiaoyun/train/feature_transform.txt.80dim-l2r2 ]; then
      cp speech_charctc_kws_phone-xiaoyun/train/feature_transform.txt.80dim-l2r2 data/global_cmvn.kaldi
    else
      echo "âŒ é”™è¯¯: æ— æ³•æ‰¾åˆ° CMVN æ–‡ä»¶"
      exit 1
    fi
  fi

  echo "å¼€å§‹è’¸é¦è®­ç»ƒ ..."
  mkdir -p $dir

  cmvn_opts=
  $norm_mean && cmvn_opts="--cmvn_file data/global_cmvn.kaldi"
  $norm_var && cmvn_opts="$cmvn_opts --norm_var"

  num_gpus=$(echo $gpus | awk -F ',' '{print NF}')

  teacher_config_opt=
  if [ -n "$teacher_config" ]; then
    teacher_config_opt="--teacher_config $teacher_config"
  fi

  python -m torch.distributed.run --standalone --nnodes=1 --nproc_per_node=$num_gpus \
    wekws/bin/train_distill.py --gpus $gpus \
      --config $student_config \
      --train_data data/train/data.list \
      --cv_data data/dev/data.list \
      --model_dir $dir \
      --num_workers 8 \
      --num_keywords $num_keywords \
      --dict $dict_dir \
      --min_duration 50 \
      --seed $seed \
      --teacher_checkpoint $teacher_checkpoint \
      $teacher_config_opt \
      --kd_temperature $kd_temperature \
      --kd_lambda_init $kd_lambda_init \
      --kd_lambda_final $kd_lambda_final \
      --kd_lambda_switch_epoch $kd_lambda_switch_epoch \
      --finetune_epochs $finetune_epochs \
      --init_from_teacher $init_from_teacher \
      $cmvn_opts

  if [ $? -ne 0 ]; then
    echo "âŒ è’¸é¦è®­ç»ƒå¤±è´¥ï¼"
    exit 1
  fi
  echo ""
  echo "âœ… Stage 2 è’¸é¦è®­ç»ƒå®Œæˆï¼"
fi


# ================================================================
# Stage 3: æ¨¡å‹å¹³å‡ + è¯„æµ‹
# ================================================================
if [ ${stage_int} -le 3 ] && [ ${stop_stage_int} -ge 3 ]; then
  echo ""
  echo "================================================"
  echo "ğŸ“Š Stage 3: æ¨¡å‹å¹³å‡ + è¯„æµ‹"
  echo "================================================"
  echo ""

  if $average_model; then
    echo "æ¨¡å‹å¹³å‡: æœ€å ${num_average} ä¸ª epoch (val_best)..."
    python wekws/bin/average_model.py \
      --dst_model $score_checkpoint \
      --src_path $dir \
      --num ${num_average} \
      --val_best

    if [ $? -ne 0 ]; then
      echo "âŒ æ¨¡å‹å¹³å‡å¤±è´¥ï¼"
      exit 1
    fi
  fi

  result_dir=$dir/test_$(basename $score_checkpoint)
  mkdir -p $result_dir

  echo "æ¨ç†è¯„æµ‹ä¸­..."
  python wekws/bin/score_ctc.py \
    --config $dir/config.yaml \
    --test_data data/test/data.list \
    --gpu 0 \
    --batch_size 256 \
    --checkpoint $score_checkpoint \
    --dict $dict_dir \
    --score_file $result_dir/score.txt \
    --num_workers 8 \
    --keywords "\u55e8\u5c0f\u95ee,\u4f60\u597d\u95ee\u95ee" \
    --token_file $token_file \
    --lexicon_file $lexicon_file

  if [ $? -ne 0 ]; then
    echo "âŒ æ¨ç†å¤±è´¥ï¼"
    exit 1
  fi

  echo "è®¡ç®— DET æ›²çº¿..."
  python wekws/bin/compute_det_ctc.py \
    --keywords "\u55e8\u5c0f\u95ee,\u4f60\u597d\u95ee\u95ee" \
    --test_data data/test/data.list \
    --window_shift $window_shift \
    --step 0.001 \
    --score_file $result_dir/score.txt \
    --dict $dict_dir \
    --token_file $token_file \
    --lexicon_file $lexicon_file

  if [ $? -ne 0 ]; then
    echo "âŒ DET è®¡ç®—å¤±è´¥ï¼"
    exit 1
  fi

  echo ""
  echo "âœ… Stage 3 è¯„æµ‹å®Œæˆï¼ç»“æœä¿å­˜åœ¨: $result_dir"
fi


# è„šæœ¬ç»“æŸæ—¥å¿—
if [ -n "$LOG_REDIRECT_DONE" ]; then
  echo ""
  echo "================================================"
  echo "âœ… è¿è¡Œå®Œæˆ: $(date)"
  echo "   å®éªŒç›®å½•: $dir"
  echo "   æ—¥å¿—æ–‡ä»¶: $log_file"
  echo "================================================"
fi
