#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“æ„å»ºè„šæœ¬ - Stage 1.5
ä½œè€…: Wayne
åŠŸèƒ½: å°†æ‰€æœ‰æ•°æ®é›†çš„å…ƒæ•°æ®æ•´åˆåˆ°SQLiteæ•°æ®åº“ï¼Œæ”¯æŒå¿«é€ŸæŸ¥è¯¢å’Œç­›é€‰
"""

import os
import sys
import json
import sqlite3
import argparse
from pathlib import Path
from tqdm import tqdm


def create_database(db_path):
    """
    åˆ›å»ºæ•°æ®åº“å’Œè¡¨ç»“æ„
    """
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # åˆ›å»ºä¸»è¡¨
    cursor.execute('''
        CREATE TABLE IF NOT EXISTS audio_metadata (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            utt_id TEXT UNIQUE NOT NULL,
            dataset TEXT NOT NULL,
            split TEXT NOT NULL,
            label_type TEXT NOT NULL,
            
            -- éŸ³é¢‘ä¿¡æ¯
            wav_path TEXT NOT NULL,
            duration REAL,
            text_content TEXT,
            
            -- å½•éŸ³æ¡ä»¶
            distance TEXT,
            angle TEXT,
            noise_volume TEXT,
            noise_type TEXT,
            
            -- è¯´è¯äººä¿¡æ¯
            gender TEXT,
            age INTEGER,
            speaker_id TEXT,
            
            -- å…¶ä»–
            keyword_id INTEGER,
            
            -- ç´¢å¼•æ—¶é—´
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # åˆ›å»ºç´¢å¼•ä»¥åŠ é€ŸæŸ¥è¯¢
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_utt_id ON audio_metadata(utt_id)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_split ON audio_metadata(split)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_gender ON audio_metadata(gender)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_age ON audio_metadata(age)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_distance ON audio_metadata(distance)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_noise_volume ON audio_metadata(noise_volume)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_noise_type ON audio_metadata(noise_type)')
    cursor.execute('CREATE INDEX IF NOT EXISTS idx_label_type ON audio_metadata(label_type)')
    
    conn.commit()
    return conn


def load_json_metadata(json_path):
    """
    åŠ è½½JSONå…ƒæ•°æ®æ–‡ä»¶
    """
    with open(json_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    return data


def load_data_list(data_list_path):
    """
    åŠ è½½ data.list æ–‡ä»¶ï¼ˆJSON Linesæ ¼å¼ï¼‰
    """
    data_dict = {}
    with open(data_list_path, 'r', encoding='utf-8') as f:
        for line in f:
            item = json.loads(line.strip())
            data_dict[item['key']] = item
    return data_dict


def parse_age(age_str):
    """
    è§£æå¹´é¾„å­—ç¬¦ä¸²ä¸ºæ•´æ•°
    """
    try:
        return int(age_str)
    except:
        return None


def parse_noise_volume(noise_volume_str):
    """
    è§£æå™ªå£°éŸ³é‡å­—ç¬¦ä¸²ï¼ˆå¦‚ "00db" -> 0, "10db" -> 10ï¼‰
    """
    try:
        return noise_volume_str.replace('db', '')
    except:
        return noise_volume_str


def insert_metadata_batch(conn, metadata_list):
    """
    æ‰¹é‡æ’å…¥å…ƒæ•°æ®
    """
    cursor = conn.cursor()
    
    cursor.executemany('''
        INSERT OR REPLACE INTO audio_metadata 
        (utt_id, dataset, split, label_type, wav_path, duration, text_content,
         distance, angle, noise_volume, noise_type, gender, age, speaker_id, keyword_id)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
    ''', metadata_list)
    
    conn.commit()


def process_split(conn, project_dir, split_name, dataset_name='mobvoi_hotword'):
    """
    å¤„ç†å•ä¸ªæ•°æ®é›†åˆ†å‰²ï¼ˆtrain/dev/testï¼‰
    """
    print(f"\nå¤„ç† {split_name} æ•°æ®é›†...")
    
    # è·¯å¾„
    resources_dir = os.path.join(project_dir, 'data/mobvoi_hotword_dataset_resources')
    data_list_path = os.path.join(project_dir, f'data/{split_name}/data.list')
    
    # åŠ è½½ data.listï¼ˆåŒ…å«durationå’Œtextï¼‰
    print(f"  åŠ è½½ data.list...")
    data_dict = load_data_list(data_list_path)
    print(f"  âœ… åŠ è½½äº† {len(data_dict)} æ¡è®°å½•")
    
    # åŠ è½½å…ƒæ•°æ®JSONæ–‡ä»¶
    metadata_all = []
    
    for label_type in ['p', 'n']:  # p=positive, n=negative
        json_path = os.path.join(resources_dir, f'{label_type}_{split_name}.json')
        
        if not os.path.exists(json_path):
            print(f"  âš ï¸  è·³è¿‡ {json_path}ï¼ˆæ–‡ä»¶ä¸å­˜åœ¨ï¼‰")
            continue
        
        print(f"  åŠ è½½ {label_type}_{split_name}.json...")
        metadata_json = load_json_metadata(json_path)
        print(f"  âœ… åŠ è½½äº† {len(metadata_json)} æ¡å…ƒæ•°æ®")
        
        # åˆå¹¶æ•°æ®
        metadata_batch = []
        missing_count = 0
        
        for item in tqdm(metadata_json, desc=f"  å¤„ç† {label_type}_{split_name}"):
            utt_id = item['utt_id']
            
            # ä» data.list ä¸­è·å– duration å’Œ text
            data_info = data_dict.get(utt_id, {})
            
            if not data_info:
                missing_count += 1
                continue
            
            # å‡†å¤‡æ’å…¥æ•°æ®
            metadata_batch.append((
                utt_id,
                dataset_name,
                split_name,
                'positive' if label_type == 'p' else 'negative',
                data_info.get('wav', ''),
                data_info.get('duration', 0.0),
                data_info.get('txt', ''),
                item.get('distance', ''),
                item.get('angle', ''),
                parse_noise_volume(item.get('noise_volume', '')),
                item.get('noise_type', ''),
                item.get('gender', ''),
                parse_age(item.get('age', '')),
                item.get('speaker_id', ''),
                item.get('keyword_id', 0)
            ))
        
        # æ‰¹é‡æ’å…¥
        if metadata_batch:
            insert_metadata_batch(conn, metadata_batch)
            print(f"  âœ… æ’å…¥äº† {len(metadata_batch)} æ¡è®°å½•åˆ°æ•°æ®åº“")
        
        if missing_count > 0:
            print(f"  âš ï¸  æœ‰ {missing_count} æ¡è®°å½•åœ¨ data.list ä¸­æœªæ‰¾åˆ°")


def print_statistics(conn):
    """
    æ‰“å°æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯
    """
    cursor = conn.cursor()
    
    print("\n" + "="*60)
    print("æ•°æ®åº“ç»Ÿè®¡ä¿¡æ¯")
    print("="*60)
    
    # æ€»è®°å½•æ•°
    cursor.execute("SELECT COUNT(*) FROM audio_metadata")
    total_count = cursor.fetchone()[0]
    print(f"\næ€»è®°å½•æ•°: {total_count:,}")
    
    # æŒ‰splitç»Ÿè®¡
    print("\næŒ‰æ•°æ®é›†åˆ†å‰²ç»Ÿè®¡:")
    cursor.execute("""
        SELECT split, COUNT(*) as count 
        FROM audio_metadata 
        GROUP BY split
        ORDER BY count DESC
    """)
    for row in cursor.fetchall():
        print(f"  {row[0]:10s}: {row[1]:8,} æ¡")
    
    # æŒ‰label_typeç»Ÿè®¡
    print("\næŒ‰æ ‡ç­¾ç±»å‹ç»Ÿè®¡:")
    cursor.execute("""
        SELECT label_type, COUNT(*) as count 
        FROM audio_metadata 
        GROUP BY label_type
        ORDER BY count DESC
    """)
    for row in cursor.fetchall():
        print(f"  {row[0]:10s}: {row[1]:8,} æ¡")
    
    # æŒ‰æ€§åˆ«ç»Ÿè®¡
    print("\næŒ‰æ€§åˆ«ç»Ÿè®¡:")
    cursor.execute("""
        SELECT gender, COUNT(*) as count 
        FROM audio_metadata 
        WHERE gender IS NOT NULL AND gender != ''
        GROUP BY gender
        ORDER BY count DESC
    """)
    for row in cursor.fetchall():
        print(f"  {row[0]:10s}: {row[1]:8,} æ¡")
    
    # æŒ‰å¹´é¾„ç»Ÿè®¡ï¼ˆå‰10ï¼‰
    print("\næŒ‰å¹´é¾„ç»Ÿè®¡ï¼ˆå‰10ï¼‰:")
    cursor.execute("""
        SELECT age, COUNT(*) as count 
        FROM audio_metadata 
        WHERE age IS NOT NULL
        GROUP BY age
        ORDER BY count DESC
        LIMIT 10
    """)
    for row in cursor.fetchall():
        print(f"  {row[0]:3d} å²: {row[1]:8,} æ¡")
    
    # æŒ‰è·ç¦»ç»Ÿè®¡
    print("\næŒ‰è·ç¦»ç»Ÿè®¡:")
    cursor.execute("""
        SELECT distance, COUNT(*) as count 
        FROM audio_metadata 
        WHERE distance IS NOT NULL AND distance != ''
        GROUP BY distance
        ORDER BY distance
    """)
    for row in cursor.fetchall():
        print(f"  {row[0]:10s}: {row[1]:8,} æ¡")
    
    # æŒ‰å™ªå£°éŸ³é‡ç»Ÿè®¡
    print("\næŒ‰å™ªå£°éŸ³é‡ç»Ÿè®¡:")
    cursor.execute("""
        SELECT noise_volume, COUNT(*) as count 
        FROM audio_metadata 
        WHERE noise_volume IS NOT NULL AND noise_volume != ''
        GROUP BY noise_volume
        ORDER BY noise_volume
    """)
    for row in cursor.fetchall():
        print(f"  {row[0]:10s}: {row[1]:8,} æ¡")
    
    # æŒ‰å™ªå£°ç±»å‹ç»Ÿè®¡
    print("\næŒ‰å™ªå£°ç±»å‹ç»Ÿè®¡:")
    cursor.execute("""
        SELECT noise_type, COUNT(*) as count 
        FROM audio_metadata 
        WHERE noise_type IS NOT NULL AND noise_type != ''
        GROUP BY noise_type
        ORDER BY count DESC
    """)
    for row in cursor.fetchall():
        print(f"  {row[0]:15s}: {row[1]:8,} æ¡")
    
    print("\n" + "="*60)


def main():
    parser = argparse.ArgumentParser(
        description='æ„å»ºéŸ³é¢‘å…ƒæ•°æ®æ•°æ®åº“ï¼ˆStage 1.5ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python generate_metadata_db.py
  python generate_metadata_db.py --output-db ./metadata.db
  python generate_metadata_db.py --splits train dev test
        """
    )
    
    parser.add_argument(
        '--output-db',
        type=str,
        default=None,
        help='è¾“å‡ºæ•°æ®åº“è·¯å¾„ï¼ˆé»˜è®¤: data/metadata.dbï¼‰'
    )
    
    parser.add_argument(
        '--splits',
        nargs='+',
        default=['train', 'dev', 'test'],
        help='è¦å¤„ç†çš„æ•°æ®é›†åˆ†å‰²ï¼ˆé»˜è®¤: train dev testï¼‰'
    )
    
    parser.add_argument(
        '--force',
        action='store_true',
        help='å¼ºåˆ¶é‡å»ºæ•°æ®åº“ï¼ˆåˆ é™¤å·²å­˜åœ¨çš„æ•°æ®åº“ï¼‰'
    )
    
    args = parser.parse_args()
    
    # è·å–é¡¹ç›®ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_dir = os.path.dirname(script_dir)
    
    # è®¾ç½®æ•°æ®åº“è·¯å¾„
    if args.output_db:
        db_path = args.output_db
    else:
        db_path = os.path.join(project_dir, 'data/metadata.db')
    
    print("="*60)
    print("éŸ³é¢‘å…ƒæ•°æ®æ•°æ®åº“æ„å»ºå·¥å…·")
    print("="*60)
    print(f"é¡¹ç›®ç›®å½•: {project_dir}")
    print(f"æ•°æ®åº“è·¯å¾„: {db_path}")
    print(f"å¤„ç†æ•°æ®é›†: {', '.join(args.splits)}")
    print("="*60)
    
    # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å·²å­˜åœ¨
    if os.path.exists(db_path):
        if args.force:
            print(f"\nâš ï¸  åˆ é™¤å·²å­˜åœ¨çš„æ•°æ®åº“: {db_path}")
            os.remove(db_path)
        else:
            print(f"\nâš ï¸  æ•°æ®åº“å·²å­˜åœ¨: {db_path}")
            response = input("æ˜¯å¦è¦é‡å»ºæ•°æ®åº“ï¼Ÿè¿™å°†åˆ é™¤æ‰€æœ‰ç°æœ‰æ•°æ®ã€‚(y/N): ")
            if response.lower() != 'y':
                print("å–æ¶ˆæ“ä½œã€‚")
                sys.exit(0)
            os.remove(db_path)
    
    try:
        # åˆ›å»ºæ•°æ®åº“
        print("\nğŸ“Š åˆ›å»ºæ•°æ®åº“ç»“æ„...")
        conn = create_database(db_path)
        print("âœ… æ•°æ®åº“åˆ›å»ºæˆåŠŸ")
        
        # å¤„ç†å„ä¸ªæ•°æ®é›†åˆ†å‰²
        for split in args.splits:
            process_split(conn, project_dir, split)
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print_statistics(conn)
        
        # å…³é—­æ•°æ®åº“
        conn.close()
        
        print(f"\nâœ… æ•°æ®åº“æ„å»ºå®Œæˆï¼")
        print(f"ğŸ“ æ•°æ®åº“ä½ç½®: {db_path}")
        print(f"ğŸ’¾ æ•°æ®åº“å¤§å°: {os.path.getsize(db_path) / 1024 / 1024:.2f} MB")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
